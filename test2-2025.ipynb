{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b51d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carefully modify the below two string variables. Ensure there are no typos.\n",
    "\n",
    "student_id = \"11093712\" # set this to your student ID\n",
    "\n",
    "student_mail = \"matthew.crean@student.manchester.ac.uk\" # your email address"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef390d5",
   "metadata": {},
   "source": [
    "# Coursework 2\n",
    "\n",
    "This coursework test contains several Jupyter Notebook cells with the comment `# TODO`. This is where you type the code for your solutions. Do not alter any of the other cells. \n",
    "\n",
    "It is good practice to include markdown cells explaining your work, but in this test they won't be marked. \n",
    "\n",
    "Here are some tips:\n",
    "\n",
    "* **Do not alter the names of the predefined variables and functions,** such as `h_best_L1`, `astro_scores`, etc. The (return) values of these variables and functions will inform the marking. Renaming them and failure to follow the problem description will result in loss of marks.\n",
    "\n",
    "* **Ensure that functions *return* values, not merely print them.** Each function should have at least one occurance of the `return` keyword, followed by a variable of the type required by the question.  \n",
    "\n",
    "* **Do not hard-code any solution variables.** All problems must be solved by computer code using the data in the provided CSV file. For example, do *not* simply define a variable `astro_scores = 1234` with a fixed value. Your Jupyter Notebook should produce results with a modified data file that has the same format but different numerical (or NaN) values.\n",
    "\n",
    "* **Avoid inefficient computations.** Ensure that each cell can be run in about 20 seconds on a modern laptop. Long-running cells will be timed out which will result in loss of marks.\n",
    "\n",
    "* **Submit this test as a single .ipynb file using Blackboard.** You can simply keep the name `test2-2025.ipynb`. There is a basic testing code at the end that verifies some parts of the coursework.\n",
    "\n",
    "   <span style=\"color:blue; font-weight:bold\">Strict deadline: Monday, 24th of March 2025, at 1pm. There are no automatic extensions.</span>\n",
    "\n",
    "### Note on independent work\n",
    "\n",
    "You need to complete all coursework tests independently on your own, but you are allowed to use online resources and all course notes and exercise solutions. The course notes from chapters 1 to 5 contain all that is required to solve the below problems. You are not allowed to ask other humans for help. In particular, you are not allowed to send, give, or receive code or markdown content to/from classmates and others.\n",
    "\n",
    "The University Guidelines for Academic Malpractice apply: http://documents.manchester.ac.uk/display.aspx?DocID=2870\n",
    "\n",
    "**Important: Even if you are the originator of the work** (and not the one who copied), the University Guidelines require that you will be equally responsible for this case of academic malpractice and may lose all coursework marks (or even be assigned 0 marks for the course)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2295b152",
   "metadata": {},
   "source": [
    "# Start of test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc2a253-d922-4124-931c-d4a90308d222",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-34389c5497ccc8a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4a10eb-93d7-44fa-bbf3-9c3de7025d2e",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-404456cc35ae4faa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problem 1a\n",
    "\n",
    "Consider a supervised learning problem on a $d$-dimensional feature space $\\mathcal{X}=\\mathbb{Z}^d$ with integer coordinates, and a $J$-dimensional label space $\\mathcal{Y} = \\mathbb{R}^J$ (notation as in the semester 1 lecture notes). Assume that the loss function is the $L^1$ loss, i.e., $L(y,y') = \\| y - y' \\|_1$ with the 1-norm. Further assume that we are given data pairs $(x_1,y_1),(x_2,y_2),\\ldots,(x_N,y_N) \\in \\mathcal{X}\\times \\mathcal{Y}$.\n",
    "\n",
    "Now consider the best $L^1$ hypothesis given the data, i.e., the optimal hypothesis $h$ that minimizes the empirical error \n",
    "$$\n",
    "\\hat{R}(h) := \\frac{1}{N}\\sum_{n=1}^N L(y_n, h(x_n)).\n",
    "$$ \n",
    "Implement a function `h_best_L1(x, X, Y)` that evaluates this best hypothesis for a given feature point `x`.  \n",
    "\n",
    "The inputs of `h_best_L1(x, X, Y)` are\n",
    "\n",
    "* a $d$-dimensional NumPy vector `x` which can always be assumed (without checking) to be among the feature vectors $\\{x_1,\\ldots,x_N\\}$\n",
    "\n",
    "* an $N\\times d$ NumPy matrix `X` of the features\n",
    "\n",
    "* an $N\\times J$ NumPy matrix `Y` of the labels\n",
    "\n",
    "The function returns a $J$-dimensional NumPy vector. \n",
    "\n",
    "All data types are standard floats, even if we only ever use integer values in `x` and `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b3dc6c4-7547-4614-b0a7-7bab6a2d05e6",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ducks-mean",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "h_best_L1 = None\n",
    "\n",
    "def h_best_L1(x, X, Y):\n",
    "    index = np.where((X==x).all(axis=1))\n",
    "    return Y[index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d064c0",
   "metadata": {},
   "source": [
    "## Problem 1b\n",
    "\n",
    "Write a function `best_L1_err(X, Y)` that, given data as in Problem 1a, returns the empirical error of the best $L^1$ hypothesis as a floating point number.\n",
    "\n",
    "(The function `best_L1_err` may of course make use of `h_best_L1` by calling it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d999032",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_L1_err = None\n",
    "\n",
    "def best_L1_err(X,Y):\n",
    "    Rh = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        Rh += np.sum(abs(Y[i:i+1,:] - h_best_L1(X[i:i+1,:], X, Y)))/X.shape[0]\n",
    "    return Rh"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ab13b0c0",
   "metadata": {},
   "source": [
    "## Problem 2a\n",
    "\n",
    "Using only plain Python with no modules except NumPy, write a function `my_knn(x, X, k)` that takes as inputs a $d$-dimensional NumPy vector `x` and an $N\\times d$ NumPy array `X` (each row corresponding to a data point). The parameter `k` is a positive integer. The function returns a Python list with the indices of $k$ nearest neighbours to `x` in `X`, where distance between two $d$-dimensional vectors $\\mathbf u = [u_0,u_1,\\ldots,u_{d-1}]$ and $\\mathbf v = [v_0,v_1,\\ldots,v_{d-1}]$ is measured as\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "with $p(i)$ taking the value $2$ for even $i$, and $1$ for odd $i$. \n",
    "\n",
    "The indices in the returned list should be ordered by nondecreasing distance of the data points to `x`, i.e., `X[my_knn(x, X, 1)[0],:]` is a data point closest to `x`. If there are multiple points in `X` with the exact same distance to `x`, the returned indices should be increasing.\n",
    "\n",
    "**Example:** Assume that $k=4$ and the nearest neighbours to `x` are `X[7,:], X[2,:], X[9,:], X[0,:]` with distances $1.2,5.3,3.1,1.2$, respectively. Then the returned list should be `[0, 7, 9, 2]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267a76b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_knn = None\n",
    "\n",
    "def evenodd(i):\n",
    "    if i % 2 == 0:\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "def dist(u,v):\n",
    "    return np.sum(np.abs(u - v) ** np.array(np.vectorize(evenodd)(np.arange(len(u)))))\n",
    "\n",
    "def my_knn(x, X, k):\n",
    "    y = np.apply_along_axis(dist, 1, X, x)\n",
    "    return list(np.argsort(y)[:k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08dd3d5",
   "metadata": {},
   "source": [
    "## Problem 2b\n",
    "\n",
    "Using only plain Python with no modules except NumPy, write a function `my_knn_predict(x, X, k, y)` that takes the same inputs as the function in Problem 2a, as well as a Python list `y` with `N` elements (the labels of each data point). The function then returns a label (an element of `y`) that appeared most frequently among the $k$ nearest neighbors. If there are multiple labels with the same number of votes, a label with an associated feature closest to `x` is preferred. \n",
    "\n",
    "The function `my_knn_predict` may of course make use of `my_knn` by calling it.\n",
    "\n",
    "**Example:** Assume that $k=5$ and the labels of the nearest neighbours sorted by nondecreasing distance from `x` are `['c', 'b', 'a', 'a', 'b']`. In this case `b` should be returned, as `b` is one of the most frequent labels, and there is a data point labelled `b` which is potentially closer to `x` than the next data point labelled `a`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e47f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_knn_predict = None\n",
    "\n",
    "def most_frequent(List):\n",
    "    z = np.unique(List, return_counts=True)\n",
    "    return z[0][max(z[1]) == z[1]]\n",
    "\n",
    "def my_knn_predict(x, X, k, y):\n",
    "    y = np.array(y)\n",
    "    y_knn = y[my_knn(x, X, k)]\n",
    "    mfy_knn = most_frequent(y_knn)\n",
    "    if len(mfy_knn) == 1:\n",
    "        return mfy_knn[0]\n",
    "    a = np.in1d(y_knn, mfy_knn)\n",
    "    return y_knn[a][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de436669",
   "metadata": {},
   "source": [
    "## Problem 3a\n",
    "\n",
    "We will now work with some astronomical observation data used to classify celestial objects. Some missing values are given as $-9999$, and those are removed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93697d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obj_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>delta</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run_ID</th>\n",
       "      <th>rerun_ID</th>\n",
       "      <th>cam_col</th>\n",
       "      <th>field_ID</th>\n",
       "      <th>spec_obj_ID</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>MJD</th>\n",
       "      <th>fiber_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>135.689107</td>\n",
       "      <td>32.494632</td>\n",
       "      <td>23.87882</td>\n",
       "      <td>22.27530</td>\n",
       "      <td>20.39501</td>\n",
       "      <td>19.16573</td>\n",
       "      <td>18.79371</td>\n",
       "      <td>3606</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>6.543777e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.634794</td>\n",
       "      <td>5812</td>\n",
       "      <td>56354</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.237665e+18</td>\n",
       "      <td>144.826101</td>\n",
       "      <td>31.274185</td>\n",
       "      <td>24.77759</td>\n",
       "      <td>22.83188</td>\n",
       "      <td>22.58444</td>\n",
       "      <td>21.16812</td>\n",
       "      <td>21.61427</td>\n",
       "      <td>4518</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>1.176014e+19</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.779136</td>\n",
       "      <td>10445</td>\n",
       "      <td>58158</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>142.188790</td>\n",
       "      <td>35.582444</td>\n",
       "      <td>25.26307</td>\n",
       "      <td>22.66389</td>\n",
       "      <td>20.60976</td>\n",
       "      <td>19.34857</td>\n",
       "      <td>18.94827</td>\n",
       "      <td>3606</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>5.152200e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.644195</td>\n",
       "      <td>4576</td>\n",
       "      <td>55592</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.237663e+18</td>\n",
       "      <td>338.741038</td>\n",
       "      <td>-0.402828</td>\n",
       "      <td>22.13682</td>\n",
       "      <td>23.77656</td>\n",
       "      <td>21.61162</td>\n",
       "      <td>20.50454</td>\n",
       "      <td>19.25010</td>\n",
       "      <td>4192</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>214</td>\n",
       "      <td>1.030107e+19</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.932346</td>\n",
       "      <td>9149</td>\n",
       "      <td>58039</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.237680e+18</td>\n",
       "      <td>345.282593</td>\n",
       "      <td>21.183866</td>\n",
       "      <td>19.43718</td>\n",
       "      <td>17.58028</td>\n",
       "      <td>16.49747</td>\n",
       "      <td>15.97711</td>\n",
       "      <td>15.54461</td>\n",
       "      <td>8102</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>6.891865e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.116123</td>\n",
       "      <td>6121</td>\n",
       "      <td>56187</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         obj_ID       alpha      delta         u         g         r  \\\n",
       "0  1.237661e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
       "1  1.237665e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
       "2  1.237661e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
       "3  1.237663e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
       "4  1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
       "\n",
       "          i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
       "0  19.16573  18.79371    3606       301        2        79  6.543777e+18   \n",
       "1  21.16812  21.61427    4518       301        5       119  1.176014e+19   \n",
       "2  19.34857  18.94827    3606       301        2       120  5.152200e+18   \n",
       "3  20.50454  19.25010    4192       301        3       214  1.030107e+19   \n",
       "4  15.97711  15.54461    8102       301        3       137  6.891865e+18   \n",
       "\n",
       "    class  redshift  plate    MJD  fiber_ID  \n",
       "0  GALAXY  0.634794   5812  56354       171  \n",
       "1  GALAXY  0.779136  10445  58158       427  \n",
       "2  GALAXY  0.644195   4576  55592       299  \n",
       "3  GALAXY  0.932346   9149  58039       775  \n",
       "4  GALAXY  0.116123   6121  56187       842  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not change code in this cell\n",
    "astro = pd.read_csv(\"_datasets/star_classification.csv\")\n",
    "astro.replace(-9999, np.nan, inplace=True)\n",
    "astro.dropna(inplace=True)\n",
    "astro.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea9df5d",
   "metadata": {},
   "source": [
    "We only retain the columns named *u*, *g*, *r*, *i*, *z*, and *redshift*, and let `y` be the column *class*. We then split into training and testing data as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d891215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change code in this cell\n",
    "X = astro[[\"u\", \"g\", \"r\", \"i\", \"z\", \"redshift\"]]\n",
    "y = astro[\"class\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=3383 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77762268",
   "metadata": {},
   "source": [
    "For each value $k=2,3,\\ldots,6$, train a kNN classifier with $k$ neighbors, in a pipeline with z-score standardization, on the training set. Find the accuracy score of the trained model on the test. Produce a series `astro_scores` indexed by values of $k$ whose values are the accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "407f0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "astro_scores = None\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "astro_scores_list = []\n",
    "\n",
    "for k in range(2,7):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('knn', knn)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    acc = pipe.score(X_test, y_test)\n",
    "    astro_scores_list.append(acc)\n",
    "\n",
    "astro_scores = pd.Series(astro_scores_list, index=range(2,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ece137",
   "metadata": {},
   "source": [
    "## Problem 3b\n",
    "\n",
    "Build your own sklearn Pipeline called `astro_pipe` that classifies the data from Problem 3a. You can use any scaling functions or models as part of this pipeline. Tune the parameters to achieve highest possible classification accuracy on test sets made up of 20% of the overall data.\n",
    "\n",
    "There are two requirements:\n",
    "\n",
    "* training and prediction times should be below 20 seconds, respectively, to avoid timeouts\n",
    "\n",
    "* your final pipeline should be called `astro_pipe` and it should provide the usual `astro_pipe.fit()` and `astro_pipe.predict()` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "758b483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "astro_pipe = None\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "astro_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('classifier', HistGradientBoostingClassifier(\n",
    "        max_iter=300,\n",
    "        max_depth=10,\n",
    "        random_state=3383,\n",
    "        max_leaf_nodes=30\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a227a",
   "metadata": {},
   "source": [
    "# End of test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30d8cb",
   "metadata": {},
   "source": [
    "You can use the below tests to get an indication if part of your work returns the right data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "281d2d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKAY - student_mail appears to be valid\n",
      "OKAY - h_best_L1 should be a function\n",
      "OKAY - h_best_L1 returns a value\n",
      "OKAY - best_L1_err should be a function\n",
      "OKAY - best_L1_err returns a value\n",
      "OKAY - my_knn should be a function\n",
      "OKAY - my_knn returns a value\n",
      "OKAY - my_knn_predict returns a value\n",
      "OKAY - my_knn_predict should be a function\n",
      "OKAY - astro_scores should be a pandas series\n",
      "OKAY - astro_pipe should provide fit and predict methods\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    import re\n",
    "    assert re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$', student_mail) and not 'firstname' in student_mail\n",
    "    print(\"OKAY - student_mail appears to be valid\")\n",
    "except:\n",
    "    print(\"WARN - student_mail could not be verified\")\n",
    "\n",
    "try: \n",
    "    assert callable(h_best_L1)\n",
    "    print(\"OKAY - h_best_L1 should be a function\")\n",
    "except:\n",
    "    print(\"FAIL - h_best_L1 should be a function\")\n",
    "\n",
    "import numpy as np\n",
    "X = np.array([[1,2,3],[2,-3,4],[1,2,3],[2,2,2]])\n",
    "Y = np.array([[1,2],[1,2],[3,4],[1,2]])\n",
    "x = np.array([1,2,3])\n",
    "\n",
    "try:\n",
    "    val = h_best_L1(x, X, Y)\n",
    "    assert val is not None\n",
    "    print(\"OKAY - h_best_L1 returns a value\")\n",
    "except:\n",
    "    print(\"FAIL - h_best_L1 does not return a value\")\n",
    "\n",
    "try: \n",
    "    assert callable(best_L1_err)\n",
    "    print(\"OKAY - best_L1_err should be a function\")\n",
    "except:\n",
    "    print(\"FAIL - best_L1_err should be a function\")\n",
    "\n",
    "try:\n",
    "    val = best_L1_err(X, Y)\n",
    "    assert val is not None\n",
    "    print(\"OKAY - best_L1_err returns a value\")\n",
    "except:\n",
    "    print(\"FAIL - best_L1_err does not return a value\")\n",
    "\n",
    "try: \n",
    "    assert callable(my_knn)\n",
    "    print(\"OKAY - my_knn should be a function\")\n",
    "except:\n",
    "    print(\"FAIL - my_knn should be a function\")\n",
    "\n",
    "try:\n",
    "    val = my_knn(x, X, k=2)\n",
    "    assert val is not None\n",
    "    print(\"OKAY - my_knn returns a value\")\n",
    "except:\n",
    "    print(\"FAIL - my_knn does not return a value\")\n",
    "\n",
    "try:\n",
    "    val = my_knn_predict(x, X, 2, x)\n",
    "    assert val is not None\n",
    "    print(\"OKAY - my_knn_predict returns a value\")\n",
    "except:\n",
    "    print(\"FAIL - my_knn_predict does not return a value\")\n",
    "\n",
    "try: \n",
    "    assert callable(my_knn_predict)\n",
    "    print(\"OKAY - my_knn_predict should be a function\")\n",
    "except:\n",
    "    print(\"FAIL - my_knn_predict should be a function\")\n",
    "\n",
    "try: \n",
    "    assert type(astro_scores) == pd.Series\n",
    "    print(\"OKAY - astro_scores should be a pandas series\")\n",
    "except:\n",
    "    print(\"FAIL - astro_scores should be a pandas series\")\n",
    "\n",
    "try: \n",
    "    assert callable(astro_pipe.fit) and callable(astro_pipe.predict)\n",
    "    print(\"OKAY - astro_pipe should provide fit and predict methods\")\n",
    "except:\n",
    "    print(\"FAIL - astro_pipe should provide fit and predict methods\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
